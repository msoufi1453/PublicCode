{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cb4a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6b04276",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea760bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63499874",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b87afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pytorch tensor\n",
    "N = torch.zeros((27,27), dtype=torch.int32)\n",
    "chars = sorted(list(set(''.join(words)))) #list of chars\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}#mapping of chars to integers\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        N[stoi[ch1], stoi[ch2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b626529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample from probability distribution\n",
    "P = N.float()\n",
    "P = P / P.sum(1, keepdim = True) #our pdf array\n",
    "#check broadcasting rules to see if you can divide like this!\n",
    "#many bugs come from broadcasting rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e3e7ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axx.\n",
      "minaymoryles.\n",
      "kondlaisah.\n",
      "anchshizarie.\n",
      "odaren.\n",
      "iaddash.\n",
      "h.\n",
      "jhinatien.\n",
      "egushl.\n",
      "h.\n",
      "br.\n",
      "a.\n",
      "jayn.\n",
      "ilemannariaenien.\n",
      "be.\n",
      "f.\n",
      "akiinela.\n",
      "trttanakeroruceyaaxatona.\n",
      "lamoynayrkiedengin.\n"
     ]
    }
   ],
   "source": [
    "#generate 20 names\n",
    "ix = 0\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    while True:\n",
    "        p = P[ix] #our pdf\n",
    "        ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0: #first index is where we store the ending\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3de93e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".d: -2.9420\n",
      "de: -1.4548\n",
      "ee: -2.7769\n",
      "ez: -4.7259\n",
      "z.: -2.7072\n",
      "tensor(-14.6069)\n",
      "tensor(2.9214)\n"
     ]
    }
   ],
   "source": [
    "# calculate log likelihood to see how good our model is\n",
    "#use negative log likelihood and normalize for loss function\n",
    "log_likelihood = 0\n",
    "n = 0\n",
    "for w in ['deez']:#words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1\n",
    "        prob = torch.log(P[ix1, ix2])\n",
    "        log_likelihood += prob\n",
    "        print(f'{ch1}{ch2}: {prob:0.4f}')\n",
    "        n+=1\n",
    "print(log_likelihood)\n",
    "print(-log_likelihood/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5ee79",
   "metadata": {},
   "source": [
    "## Incorporating Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a5fbe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training set\n",
    "xs, ys = [], [] #inputs, outputs\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27,27), generator=g, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005edc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "for _ in range(100):\n",
    "    #use one hot encoding for integers to convert integer to vector\n",
    "    xenc = F.one_hot(xs, num_classes = 27).float() #need to cast to float for neural net operations\n",
    "    \n",
    "    #softmax, convert neuralnet to pdf\n",
    "    counts = (xenc @ W).exp() #exponentiate to keep everything positive\n",
    "    prob = counts/counts.sum(1, keepdims=True)\n",
    "    \n",
    "    #compute loss\n",
    "    loss = -prob[torch.arange(xs.nelement()), ys].log().mean() #-log likelihood\n",
    "    print(loss.item())\n",
    "    \n",
    "    #backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    #update with gradients\n",
    "    W.data += -50*W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a40ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mor.\n",
      "axwaninaymoryles.\n",
      "kondmaisah.\n",
      "anchshizarie.\n",
      "odaren.\n",
      "iaddash.\n",
      "h.\n",
      "jionatien.\n",
      "egvonn.\n",
      "ga.\n",
      "t.\n",
      "a.\n",
      "jayn.\n",
      "ilemannariaenien.\n",
      "ad.\n",
      "f.\n",
      "akiinela.\n",
      "trttanakerorudayaaxbrima.\n",
      "lamoyonutonadengin.\n",
      "torrederahmokallovxjos.\n"
     ]
    }
   ],
   "source": [
    "#sampling from neural net\n",
    "#generate 20 names\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
    "        logits = xenc @ W #predicted log counts\n",
    "        counts = logits.exp()\n",
    "        p = counts/counts.sum(1, keepdims = True)\n",
    "        \n",
    "        ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0: #first index is where we store the ending\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64a1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
